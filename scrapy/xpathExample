1.Find any under specific dom
eg. Find any a under div 
xpath(‘//div//a’)

2.Get attribute
xpath(‘//a/@href’)

3.Select the text
xpath(‘//a/text()’)

4.Select all elements at a specific hierarchy level 
Xpath(‘//div/*’)

5.Attribute have, starts, contains, not contains 
//have
Xpath(‘//a[@href]’)
Xpath(‘//a[@href=”http://www.nihao.com”]’)
//start
Xpath(‘//a[starts-with(@href, “http://www.”]’)
//contains
Xpath(‘//a[contains(@href, “example”)]’)
//not contains 
Xpath(‘//a[not(contains(@href, “abc”))]’)

6.Multi contains 
Xpath(‘//*[contains(@class,”ltf”) and contains(@class,”skin-vector”)]//h1//text()’)

7.Select all the URLs of links under the div element following an element whose 
Child element contains the text References 
Xpath(‘//*[text()=”References”]/../following-sibling::div//a’)

8.Get the url for every images 
Xpath(‘//img/@src’)

9.Any items containing specific attributes
Xpath(‘//*[@href=”http://www.nihao.com”]’)

Eg .
<strong class="ad-price txt-xlarge txt-emphasis" itemprop="price">
拢334.39pw</strong>
xpath('//*[@itemprop="price"][1]/text()').extract()
[u'\xa3334.39pw']

9.Combine xpath and re 
response.xpath('//*[@itemprop="price"][1]/text()').re('[.0-9]+')
[u'334.39']

10.Select first element of by analyzing following-siblings
Requirement:
<section>
        <p id="ss_main">aa</p>
        <p id="ss_main">bb</p>
        <p id="main">cc</p>
        <p id="main">dd</p>
        <p id="main">ee</p>
        <p id="ss_main">ff</p>
        <p id="main">gg</p>
        <p id="main">hh</p>
        <p id="main">ii</p>
        <p id="main">jj</p>
        <p id="ss_main">xx</p>
        <p id="ss_main">yy</p>
        <p id="ss_main">zz</p>
    </section>
you can see consecutive <p> elements which attributes is staring from ss . 
what I need is using xpath select the 1st <p> element of every group which attribute is starting from ss .

SO in above xml  <p id="ss_main">aa</p> , <p id="ss_main">ff</p> ,  <p id="ss_main">xx</p> should be selected.

Solution:
//p[starts-with(@id, 'ss')][not(preceding-sibling::p[1][starts-with(@id, 'ss')])]

11. Find sibling node after specified node is found
Requirement:
<t>
    <n></n>
    <k></k>
    <m></m>
    <k></k>
</t>

find k after m

Soluation:
//m[1]/following-sibling::k[1]

12. xpath to get the first sibling
Requirement:
<div>
<strong>Name: </strong> John Doe<br />
<strong>Phone Number: </strong> 111-111-1111<br />
<strong>Address: </strong> 111 Anywhere St.
</div>

Say that's my HTML. I can get the node whose value is "Name: " with
"//strong[.='Name: ']", but how do I get " John Doe"? 

Solution:
In [13]: Selector(text=body).xpath("//strong[.='Name: ']/following-sibling::text()[1]").extract()
Out[13]: [u' John Doe']

13. get following sibling
Requirement:
<table>
<tbody>
<tr bgcolor="#AAAAAA">
<tr>
<tr>
<tr>
<tr>
<tr>
<tr>
<tr>
<td> Color Digest </td>
<td> AgArAQICGQMVBBwTIRQHIwg0GUMURAZTBWQJcwV0AoEDAQ </td>
</tr>
<tr>
<td> Color Digest </td>
<td> 2,43,2,25,21,28,0,0,0,0,0,0,0,0,0,0,0,0,0,0,33,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, </td>
</tr>
</tbody>
</table>

I am trying to extract the Second "Color Digest" td element that has the decoded value.

Solution:
In [15]: Selector(text=body).xpath("//tr[td= ' Color Digest '][2]/td/following-sibling::td[1]").extract()
Out[15]: [u'<td> 2,43,2,25,21,28,0,0,0,0,0,0,0,0,0,0,0,0,0,0,33,7,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2
0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,5,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
0, </td>']

14. xpath-select-all-following-siblings-until-another-sibling

eg.
from scrapy.selector import Selector

body = """
<node/>
<node/>
<node id="1">content</node>
<node/>
<node/>
<node/>
<node id="2">content</node>
<node/>
<node/>
"""


tmp_xpath = '''
//node[not(text()) and preceding-sibling::node[@id][1][@id='1']]
'''

Selector(text=body).xpath(tmp_xpath).extract()

output:
Out[19]: [u'<node></node>', u'<node></node>', u'<node></node>']

explain:
where '1' is the id of the current node (generate the expression dynamically).

The expression says:

from the current context go to the parent
select those child nodes that
have no text and
from all "preceding sibling nodes that have an id" the first one must have an id of 1

otherSolution:
In [21]: Selector(text=body).xpath("//node[@id='1']/following-sibling::node[following::node[@id='2']]").extract()
Out[21]: [u'<node></node>', u'<node></node>', u'<node></node>']

15. combining-the-use-of-preceding-and-following-sibling-in-the-same-xpath-query

Requirement:
<a>
    <b property="p1">zyx</b>
    <b>wvu</b>
    <b>tsr</b>
    <b property="p2">qpo</b>
    <b>qcs</b>
</a>
I want to select the nodes between the b node who has a property="p1" and the b node who has property="p2". 
I can do either of those with the preceding-sibling and the following-sibling axis but I can't seem to find how to combine both.

Solution:
//a/b[preceding-sibling::b/@property='p1' and following-sibling::b/@property='p2']
or
//b[@property='p1']/following-sibling::b[following::b[@property='p2']]

Output:
Out[27]: [u'<b>wvu</b>', u'<b>tsr</b>']

16. xpath-sibling-condition-or

Requirement:
from scrapy.selector import Selector

body = """
<a>
    <b property="p1">zyx</b>
    <b>wvu</b>
    <tr>tsr</tr>
    <a property="p2">qpo</a>
    <b>qcs1</b>
</a>

<a>
    <b property="p1">zyx</b>
    <b>wvu</b>
    <span>tsr</span>
    <a property="p2">qpo</a>
    <b>qcs2</b>
</a>
"""

In [70]: Selector(text=body).xpath("//a//preceding-sibling::*[name()='b' or name()='span'][1]").extract()

Output:
[u'<b property="p1">zyx</b>',
 u'<b>wvu</b>',
 u'<b>qcs1</b>',
 u'<b property="p1">zyx</b>',
 u'<b>wvu</b>',
 u'<span>tsr</span>']
 
Im trying to find the first preceding-sibling of a node with OR condition.
For example , i have a node A and i try to get the first preceding-sibling B but 
if there is no B then get first preceding-siblingSPAN.

17. following siding
from scrapy.selector import Selector

body = """
 <months>
  <month name="January"></month>
  <month name="February"></month>
  <month name="March"></month>
  <month name="April"></month>
</months>
"""

Selector(text=body).xpath("//months/month[@name='February']/following-sibling::month").extract()

Output:
Out[71]: [u'<month name="March"></month>', u'<month name="April"></month>']

18. XPath how to get parents sibling inside node
from scrapy.selector import Selector

body = """
<tr>
         <td bgcolor="ffffff" height="14" width="112"><p class="boldblack">&nbsp;Price:</p></td>
         <td bgcolor="ffffff" width="296"><p class="cena2">9 000 $</p></td>
         <td bgcolor="ffffff"></td>
</tr>
"""

Selector(text=body).xpath('//tr[td[1]/p[contains(., "Price:")]]/td[2]/p/text()').extract()
Selector(text=body).xpath('//tr/td/p[ends-with(., "$")]/text()').extract()   # not done

Output:
Out[79]: [u'9 000 $']

18. xpath包含中文
eg.
  <table class="tablelist textl" cellpadding="0" cellspacing="0"> 
     <tbody>
      <tr class="h"> 
       <td colspan="3" class="l2 bold size16" id="sharetitle">TEG09-架构平台运营开发工程师（深圳）</td> 
      </tr> 
      <tr class="c bottomline"> 
       <td><span class="lightblue l2">工作地点：</span>深圳</td> 
       <td><span class="lightblue">职位类别：</span>技术类</td> 
       <td><span class="lightblue">招聘人数：</span>2人</td> 
      </tr> 
      <tr class="c"> 
       <td colspan="3" class="l2"> 
        <div class="lightblue">
         工作职责：
        </div> 
        <ul class="squareli">
         <li>负责腾讯海量在线业务（微信C2C、voip、朋友圈、腾讯视频、相册等）存储、CDN事项的运营系统开发；</li>
         <li>参与系统的需求分析、设计、编码等开发工作；</li>
         <li>参与相关系统的运营和维护工作，保证系统稳定可靠运行。</li>
        </ul> </td> 
      </tr> 
      
 In [19]: response.xpath(u'//table[@class="tablelist textl"]/tr[@class="c"]/td/ul[@class="squareli" and preceding-sibling::div[text()[contains(.,"工作职责")]]]').extract()
Out[19]: [u'<ul class="squareli"><li>\u8d1f\u8d23\u817e\u8baf\u6d77\u91cf\u5728\
u7ebf\u4e1a\u52a1\uff08\u5fae\u4fe1C2C\u3001voip\u3001\u670b\u53cb\u5708\u3001\u
817e\u8baf\u89c6\u9891\u3001\u76f8\u518c\u7b49\uff09\u5b58\u50a8\u3001CDN\u4e8b\
u9879\u7684\u8fd0\u8425\u7cfb\u7edf\u5f00\u53d1\uff1b</li><li>\u53c2\u4e0e\u7cfb
\u7edf\u7684\u9700\u6c42\u5206\u6790\u3001\u8bbe\u8ba1\u3001\u7f16\u7801\u7b49\u
5f00\u53d1\u5de5\u4f5c\uff1b</li><li>\u53c2\u4e0e\u76f8\u5173\u7cfb\u7edf\u7684\
u8fd0\u8425\u548c\u7ef4\u62a4\u5de5\u4f5c\uff0c\u4fdd\u8bc1\u7cfb\u7edf\u7a33\u5
b9a\u53ef\u9760\u8fd0\u884c\u3002</li></ul>']
