1. pass list as arguments
Override spider's __init__() method:

class MySpider(Spider):
    name = 'my_spider'    

    def __init__(self, *args, **kwargs): 
        super(MySpider, self).__init__(*args, **kwargs) 

        endpoints = kwargs.get('start_urls').split(',')
        self.start_urls = ["http://www.google.com/patents/" + x for x in endpoints]
And pass the list of endpoints through the -a command line argument:

scrapy crawl patents -a start_urls="US6249832,US20120095946" -o static/s.json

2. crawl 100 pages 
scrapy crawl -s CLOSESPIDER_PAGECOUNT=100 my_spider

3. Website forces scrapy redirect
http://stackoverflow.com/questions/39132733/website-forces-scrapy-redirect


