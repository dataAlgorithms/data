1. Proxy in the spider 
//Single Proxy
Enable HttpProxyMiddleware in your settings.py, like this:
DOWNLOADER_MIDDLEWARES = {
'scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware': 1,
}
pass proxy to request via request.meta:
request = Request(url="http://example.com")
request.meta['proxy'] = "host:port"
yield request


//Multiple Proxies
class MySpider(BaseSpider):
    name = "my_spider"
    def __init__(self, *args, **kwargs):
        super(MySpider, self).__init__(*args, **kwargs)
        self.proxy_pool = ['proxy_address1', 'proxy_address2', ..., 'proxy_addressN']

    def parse(self, response):
        ...parse code...
        if something:
            yield self.get_request(url)

    def get_request(self, url):
        req = Request(url=url)
        if self.proxy_pool:
            proxy_addr = self.proxy_pool[random.randint(0,len(self.proxy_pool) - 1)]
            req.meta['proxy'] = proxy_addr

        return req

2. Enable Proxy with custom middleware (single)
//1-Create a new file called “middlewares.py” and save it in your scrapy project and add the following code to it.

import base64

class ProxyMiddleware(object):
# overwrite process request
def process_request(self, request, spider):
    # Set the location of the proxy
    request.meta['proxy'] = "http://YOUR_PROXY_IP:PORT"

    # Use the following lines if your proxy requires authentication
    proxy_user_pass = "USERNAME:PASSWORD"
    # setup basic authentication for the proxy
    encoded_user_pass = base64.encodestring(proxy_user_pass)
    request.headers['Proxy-Authorization'] = 'Basic ' + encoded_user_pass

//2 – Open your project’s configuration file (./project_name/settings.py) and add the following code
DOWNLOADER_MIDDLEWARES = {
'scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware': 110,
'project_name.middlewares.ProxyMiddleware': 100,
}

3. Enable Proxy with custom middleware (mul)
//proxy.py
'''
This proxy is goagent/wallproxy
If you want to disable it, plz configure settings.py
'''
PROXIES = [
    #{"ip_port": "127.0.0.1:8087"}, #goagent
    #{"ip_port": "127.0.0.1:8118"}, #tor via privoxy
    {"ip_port": "127.0.0.1:1080"}, #tor via privoxy
]

//middleware.py
from proxy import PROXIES

class CustomHttpProxyMiddleware(object):

    def process_request(self, request, spider):
        # TODO implement complex proxy providing algorithm
        if self.use_proxy(request):
            p = random.choice(PROXIES)
            try:
                request.meta['proxy'] = "http://%s" % p['ip_port']
            except Exception, e:
                #log.msg("Exception %s" % e, _level=log.CRITICAL)
                log.critical("Exception %s" % e)

    def use_proxy(self, request):
        """
        using direct download for depth <= 2
        using proxy with probability 0.3
        """
        #if "depth" in request.meta and int(request.meta['depth']) <= 2:
        #    return False
        #i = random.randint(1, 10)
        #return i <= 2
        return True

//settings.py
DOWNLOADER_MIDDLEWARES = {
    'zhihu.middleware.CustomUserAgentMiddleware': 401,
}

3. Use Proxy lib
https://github.com/aivarsk/scrapy-proxies
