1. pyspark ImportError: cannot import name accumulators
Solution:
~/spark/spark/python/pyspark/context.py,
the file which was causing the error:
comment it
# from pyspark import accumulators
from pyspark.accumulators import Accumulator

2. Invalid maximum heap size
[root@RND-SM-1-59Q code]# spark-shell  --driver-memory 16G
Invalid maximum heap size: -Xmx16G
The specified size exceeds the maximum representable size.
Error: Could not create the Java Virtual Machine.
Error: A fatal exception has occurred. Program will exit.

方法:
yum remove java-1.6.0-openjdk*
yum remove java-1.7.0-openjdk*
rpm -Uvh jdk-8u144-linux-x64.rpm  (需要下载)

[root@RND-SM-1-59Q code]# spark-shell --driver-memory 8g
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/root/workspace/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/bzhou/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
17/08/21 18:54:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/08/21 18:54:17 WARN Utils: Your hostname, RND-SM-1-59Q resolves to a loopback address: 127.0.0.1; using 192.168.90.35 instead (on interface eth0)
17/08/21 18:54:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
Spark context Web UI available at http://192.168.90.35:4040
Spark context available as 'sc' (master = local[*], app id = local-1503312857876).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.1.0
      /_/
         
Using Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_144)
Type in expressions to have them evaluated.
Type :help for more information.

scala> 

3. AttributeError: 'DataFrame' object has no attribute 'map'
https://stackoverflow.com/questions/39535447/attributeerror-dataframe-object-has-no-attribute-map
